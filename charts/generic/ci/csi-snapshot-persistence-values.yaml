# Example: StatefulSet with CSI Volume Snapshots
# Demonstrates persistent storage with snapshot capabilities for backup/restore

nameOverride: "snapshot-app"

workload:
  type: statefulset
  enabled: true
  replicas: 1

  # StatefulSet specific
  serviceName: snapshot-app-headless
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0

  # Volume claim templates for StatefulSet
  volumeClaimTemplates:
    data:
      annotations:
        # Enable snapshots for this PVC
        snapshot.storage.kubernetes.io/allow-volume-snapshot: "true"
      accessModes: ["ReadWriteOnce"]
      storageClassName: gp3-csi  # CSI driver with snapshot support
      resources:
        requests:
          storage: 100Gi
    backup:
      annotations:
        snapshot.storage.kubernetes.io/allow-volume-snapshot: "true"
      accessModes: ["ReadWriteOnce"]
      storageClassName: gp3-csi
      resources:
        requests:
          storage: 50Gi

image:
  repository: postgres
  tag: "15-alpine"
  pullPolicy: IfNotPresent

deployment:
  ports:
    - name: postgres
      containerPort: 5432
      protocol: TCP

  env:
    - name: POSTGRES_DB
      value: "production"
    - name: POSTGRES_USER
      value: "postgres"
    - name: POSTGRES_PASSWORD
      valueFrom:
        secretKeyRef:
          name: postgres-secret
          key: password
    - name: PGDATA
      value: "/var/lib/postgresql/data/pgdata"
    - name: POSTGRES_INITDB_ARGS
      value: "--encoding=UTF8 --locale=en_US.UTF-8"
    - name: POSTGRES_HOST_AUTH_METHOD
      value: "scram-sha-256"

  resources:
    limits:
      memory: "2Gi"
      cpu: "2"
    requests:
      cpu: "500m"
      memory: "1Gi"

  volumeMounts:
    - name: data
      mountPath: /var/lib/postgresql/data
    - name: backup
      mountPath: /backup
    - name: postgres-config
      mountPath: /etc/postgresql
      readOnly: true
    - name: init-scripts
      mountPath: /docker-entrypoint-initdb.d
      readOnly: true

  livenessProbe:
    exec:
      command:
        - pg_isready
        - -U
        - postgres
    initialDelaySeconds: 30
    periodSeconds: 10

  readinessProbe:
    exec:
      command:
        - pg_isready
        - -U
        - postgres
    initialDelaySeconds: 5
    periodSeconds: 5

# Additional volumes
persistence:
  enabled: false  # Using volumeClaimTemplates instead

# Extra volumes for ConfigMaps
extraVolumes:
  - name: postgres-config
    configMap:
      name: postgres-config
  - name: init-scripts
    configMap:
      name: init-scripts
      defaultMode: 0755

# Headless service for StatefulSet
service:
  enabled: true
  type: ClusterIP
  clusterIP: None  # Headless service
  ports:
    - name: postgres
      port: 5432
      targetPort: postgres

# Additional service for read replicas
additionalServices:
  postgres-read:
    type: ClusterIP
    ports:
      - name: postgres
        port: 5432
        targetPort: postgres
    selector:
      app.kubernetes.io/name: "{{ include \"generic.name\" . }}"
      app.kubernetes.io/instance: "{{ .Release.Name }}"
      role: read-replica

# ConfigMaps for PostgreSQL configuration
configMap:
  enabled: true
  name: postgres-config
  data:
    postgresql.conf: |
      # Connection settings
      listen_addresses = '*'
      max_connections = 200

      # Memory settings
      shared_buffers = 512MB
      effective_cache_size = 1536MB
      maintenance_work_mem = 128MB
      work_mem = 4MB

      # WAL settings for replication
      wal_level = replica
      max_wal_senders = 10
      wal_keep_segments = 64
      archive_mode = on
      archive_command = 'cp %p /backup/archive/%f'

      # Checkpoint settings
      checkpoint_completion_target = 0.9
      checkpoint_timeout = 15min

      # Logging
      log_statement = 'all'
      log_duration = on
      log_line_prefix = '%t [%p-%l] %u@%d '
      log_checkpoints = on
      log_connections = on
      log_disconnections = on
      log_lock_waits = on
      log_temp_files = 0

      # Performance
      random_page_cost = 1.1
      effective_io_concurrency = 200

    pg_hba.conf: |
      # TYPE  DATABASE        USER            ADDRESS                 METHOD
      local   all             all                                     trust
      host    all             all             127.0.0.1/32            scram-sha-256
      host    all             all             ::1/128                 scram-sha-256
      host    all             all             0.0.0.0/0               scram-sha-256
      host    replication     all             0.0.0.0/0               scram-sha-256

additionalConfigMaps:
  init-scripts:
    data:
      01-create-backup-user.sql: |
        -- Create backup user with necessary permissions
        CREATE USER backup_user WITH REPLICATION PASSWORD 'backup_password';
        GRANT CONNECT ON DATABASE production TO backup_user;
        GRANT USAGE ON SCHEMA public TO backup_user;
        GRANT SELECT ON ALL TABLES IN SCHEMA public TO backup_user;
        ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO backup_user;

      02-create-replication-slot.sql: |
        -- Create replication slot for streaming replication
        SELECT pg_create_physical_replication_slot('replica_slot');

      03-enable-extensions.sql: |
        -- Enable useful extensions
        CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
        CREATE EXTENSION IF NOT EXISTS pgcrypto;
        CREATE EXTENSION IF NOT EXISTS uuid-ossp;

# Secret for passwords
secret:
  enabled: true
  type: Opaque
  stringData:
    password: "super-secret-password"
    replication-password: "replication-secret-password"

# Volume snapshot class
extraObjects:
  # VolumeSnapshotClass for CSI snapshots
  - apiVersion: snapshot.storage.k8s.io/v1
    kind: VolumeSnapshotClass
    metadata:
      name: csi-snapclass
      annotations:
        snapshot.storage.kubernetes.io/is-default-class: "true"
    driver: ebs.csi.aws.com  # AWS EBS CSI driver
    deletionPolicy: Retain
    parameters:
      # AWS-specific parameters
      tagSpecification_1: "ResourceType=snapshot"
      tagSpecification_2: 'Tags=[{Key=Application,Value={{ include "generic.fullname" . }}},{Key=Environment,Value=production}]'

  # Scheduled volume snapshots using CronJob
  - apiVersion: batch/v1
    kind: CronJob
    metadata:
      name: "{{ include \"generic.fullname\" . }}-snapshot-schedule"
    spec:
      schedule: "0 2 * * *"  # Daily at 2 AM
      concurrencyPolicy: Forbid
      jobTemplate:
        spec:
          template:
            spec:
              serviceAccountName: "{{ include \"generic.serviceAccountName\" . }}"
              containers:
                - name: snapshot-creator
                  image: bitnami/kubectl:latest
                  command:
                    - /bin/bash
                    - -c
                    - |
                      set -e
                      TIMESTAMP=$(date +%Y%m%d%H%M%S)

                      # Create snapshot for data volume
                      kubectl apply -f - <<EOF
                      apiVersion: snapshot.storage.k8s.io/v1
                      kind: VolumeSnapshot
                      metadata:
                        name: {{ include "generic.fullname" . }}-data-snapshot-${TIMESTAMP}
                        labels:
                          app.kubernetes.io/name: {{ include "generic.name" . }}
                          app.kubernetes.io/instance: {{ .Release.Name }}
                          snapshot.type: scheduled
                      spec:
                        volumeSnapshotClassName: csi-snapclass
                        source:
                          persistentVolumeClaimName: data-{{ include "generic.fullname" . }}-0
                      EOF

                      # Create snapshot for backup volume
                      kubectl apply -f - <<EOF
                      apiVersion: snapshot.storage.k8s.io/v1
                      kind: VolumeSnapshot
                      metadata:
                        name: {{ include "generic.fullname" . }}-backup-snapshot-${TIMESTAMP}
                        labels:
                          app.kubernetes.io/name: {{ include "generic.name" . }}
                          app.kubernetes.io/instance: {{ .Release.Name }}
                          snapshot.type: scheduled
                      spec:
                        volumeSnapshotClassName: csi-snapclass
                        source:
                          persistentVolumeClaimName: backup-{{ include "generic.fullname" . }}-0
                      EOF

                      # Delete old snapshots (keep last 7 days)
                      kubectl get volumesnapshot -l app.kubernetes.io/name={{ include "generic.name" . }},snapshot.type=scheduled \
                        --sort-by=.metadata.creationTimestamp -o json | \
                        jq -r '.items[:-14] | .[].metadata.name' | \
                        xargs -r kubectl delete volumesnapshot
              restartPolicy: OnFailure

  # Manual snapshot trigger Job
  - apiVersion: batch/v1
    kind: Job
    metadata:
      name: "{{ include \"generic.fullname\" . }}-manual-snapshot"
      annotations:
        "helm.sh/hook": post-upgrade
        "helm.sh/hook-weight": "1"
        "helm.sh/hook-delete-policy": before-hook-creation
    spec:
      template:
        spec:
          serviceAccountName: "{{ include \"generic.serviceAccountName\" . }}"
          containers:
            - name: pre-upgrade-snapshot
              image: bitnami/kubectl:latest
              command:
                - /bin/bash
                - -c
                - |
                  set -e
                  TIMESTAMP=$(date +%Y%m%d%H%M%S)

                  # Create pre-upgrade snapshot
                  kubectl apply -f - <<EOF
                  apiVersion: snapshot.storage.k8s.io/v1
                  kind: VolumeSnapshot
                  metadata:
                    name: {{ include "generic.fullname" . }}-pre-upgrade-${TIMESTAMP}
                    labels:
                      app.kubernetes.io/name: {{ include "generic.name" . }}
                      app.kubernetes.io/instance: {{ .Release.Name }}
                      snapshot.type: pre-upgrade
                      helm.revision: "{{ .Release.Revision }}"
                  spec:
                    volumeSnapshotClassName: csi-snapclass
                    source:
                      persistentVolumeClaimName: data-{{ include "generic.fullname" . }}-0
                  EOF
          restartPolicy: OnFailure

# RBAC for snapshot operations
rbac:
  enabled: true
  rules:
    - apiGroups: ["snapshot.storage.k8s.io"]
      resources: ["volumesnapshots", "volumesnapshotclasses"]
      verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
    - apiGroups: [""]
      resources: ["persistentvolumeclaims", "persistentvolumes"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["storage.k8s.io"]
      resources: ["storageclasses"]
      verbs: ["get", "list", "watch"]

# Pod disruption budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Anti-affinity to spread across zones
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - "{{ include \"generic.name\" . }}"
          topologyKey: topology.kubernetes.io/zone

# Service monitor for PostgreSQL metrics
serviceMonitor:
  enabled: true
  interval: 30s
  path: /metrics
  port: metrics
  endpoints:
    - port: postgres
      interval: 30s
      path: /metrics
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
